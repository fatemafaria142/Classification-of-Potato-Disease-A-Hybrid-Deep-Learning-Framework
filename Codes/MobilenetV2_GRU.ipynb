{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085fb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3099ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b55b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f640f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if TensorFlow can see the GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"No GPU devices available.\")\n",
    "else:\n",
    "    print(\"GPU devices available:\", physical_devices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41fbc0-8961-43a7-829b-a5131f136d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the list of physical devices\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    # Print GPU name\n",
    "    print(\"GPU Name:\", physical_devices[0].name)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05417cf6-fc5d-498d-9fbe-5f27891b0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "\n",
    "# Get the list of available GPUs\n",
    "gpus = GPUtil.getGPUs()\n",
    "\n",
    "if gpus:\n",
    "    # Print GPU name\n",
    "    print(\"GPU Name:\", gpus[0].name)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239b75d-834d-4257-8630-b34f534fb6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gputil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f660e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --extra-index-url https://pypi.nvidia.com tensorrt-bindings==8.6.1 tensorrt-libs==8.6.1\n",
    "!pip install -U tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --extra-index-url https://pypi.nvidia.com tensorrt-bindings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "print(tf.version.VERSION)\n",
    "import sys\n",
    "sys.version\n",
    "tf.config.list_physical_devices('GPU')\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Conv2D,Concatenate,Add,SeparableConv2D,ReLU,ZeroPadding2D,DepthwiseConv2D,TimeDistributed,LSTM,GRU,Bidirectional\n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense,BatchNormalization,Dropout,AveragePooling2D,Activation,GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66095211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60371f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_train = os.listdir('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\Train')\n",
    "dataset_path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2593be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_validation = os.listdir('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\validation')\n",
    "dataset_path_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591cae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_path_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_items_train=[]\n",
    "\n",
    "for item in dataset_path_train:\n",
    "  all_disease = os.listdir('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\Train' +'\\\\'+item)\n",
    "  for disease in all_disease:\n",
    "    disease_items_train.append((item , str('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\Train'+'\\\\'+item ) +'\\\\'+disease ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab22495",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_disease_df = pd.DataFrame(data=disease_items_train,columns = ['Train_Disease_Type' ,'Train_Disease_Image'])\n",
    "train_disease_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faab49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_items_test=[]\n",
    "\n",
    "for item in dataset_path_validation:\n",
    "  all_disease = os.listdir('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\validation' +'\\\\'+item)\n",
    "  for disease in all_disease:\n",
    "    disease_items_test.append((item , str('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\validation'+'\\\\'+item ) +'\\\\'+disease ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disease_df = pd.DataFrame(data=disease_items_test,columns = ['Test_Disease_Type' ,'Test_Disease_Image'])\n",
    "test_disease_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "train_images = []\n",
    "train_labels = []\n",
    "path = 'C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\Train\\\\'\n",
    "for i in dataset_path_train:\n",
    "  data_path = path+str(i)\n",
    "  file_names = [i for i in os.listdir(data_path)]\n",
    "  #print(file_names)\n",
    "  for f in file_names:\n",
    "    img = cv2.imread(data_path+'\\\\'+f)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img,(img_width,img_height))\n",
    "    train_images.append(img)\n",
    "    train_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f895620",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato\\\\validation\\\\'\n",
    "for i in dataset_path_validation:\n",
    "  data_path = path+str(i)\n",
    "  file_names = [i for i in os.listdir(data_path)]\n",
    "  #print(file_names)\n",
    "  for f in file_names:\n",
    "    img = cv2.imread(data_path+'\\\\'+f)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img,(img_width,img_height))\n",
    "    test_images.append(img)\n",
    "    test_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "print(test_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d093d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_images)\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5bba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test_images)\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = train_disease_df['Train_Disease_Type'].values\n",
    "#print(y_train)\n",
    "y_test = test_disease_df['Test_Disease_Type'].values\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61908df",
   "metadata": {},
   "outputs": [],
   "source": [
    "le =  LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)       #Label encoding for traditional Machine Leanring algorithms\n",
    "y_train_one_hot = to_categorical(y_train) # One Hot Encoding for deep learning algorithms\n",
    "\n",
    "\n",
    "le =  LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)         #Label encoding for traditional Machine Leanring algorithms\n",
    "y_test_one_hot = to_categorical(y_test)   # One Hot Encoding for deep learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(2123,1,224,224, 3)\n",
    "x_test = np.array(x_test).reshape(560,1,224,224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb87724",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train:\",x_train.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"x_test:\",x_test.shape)\n",
    "print(\"y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7797e",
   "metadata": {},
   "source": [
    "#  **Expansion Block**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansion_block(x,t,filters,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    total_filters = t*filters\n",
    "    x = TimeDistributed(Conv2D(total_filters,1,padding='same',use_bias=False, name =    prefix +'expand'))(x)\n",
    "    x = TimeDistributed(BatchNormalization(name=prefix +'expand_bn'))(x)\n",
    "    x = TimeDistributed(ReLU(6,name = prefix +'expand_relu'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff065bd",
   "metadata": {},
   "source": [
    "# Depthwise Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthwise_block(x,stride,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = TimeDistributed(DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv'))(x)\n",
    "    x = TimeDistributed(BatchNormalization(name=prefix +'dw_bn'))(x)\n",
    "    x = TimeDistributed(ReLU(6,name = prefix +'dw_relu'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9118b",
   "metadata": {},
   "source": [
    "# Projection Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61dd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_block(x,out_channels,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = TimeDistributed(Conv2D(filters=out_channels,kernel_size = 1,   padding='same',use_bias=False,name= prefix + 'compress'))(x)\n",
    "    x = TimeDistributed(BatchNormalization(name=prefix +'compress_bn'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b9da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bottleneck(x,t,filters, out_channels,stride,block_id):\n",
    "    y = expansion_block(x,t,filters,block_id)\n",
    "    y = depthwise_block(y,stride,block_id)\n",
    "    y = projection_block(y, out_channels,block_id)\n",
    "    if y.shape[-1]==x.shape[-1]:\n",
    "       y =tf.keras.layers.add([x,y])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 224\n",
    "image_width = 224\n",
    "image_channels = 3\n",
    "image_dimension = (1,image_height,image_width,image_channels)   #shape (height, width, channels)\n",
    "input_image = Input(shape = image_dimension) # inp = layers.Input((None,128,216,1), ragged=True)\n",
    "x = TimeDistributed(Conv2D(32,3,strides=(2,2),padding='same', use_bias=False))(input_image)\n",
    "x = TimeDistributed(BatchNormalization(name='conv1_bn'))(x)\n",
    "x = TimeDistributed(ReLU(6, name='conv1_relu'))(x)\n",
    "# 17 Bottlenecks\n",
    "x = depthwise_block(x,stride=1,block_id=1)\n",
    "x = projection_block(x, out_channels=16,block_id=1)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 2,block_id = 2)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 1,block_id = 3)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 320, stride = 1,block_id = 17)\n",
    "x = TimeDistributed(Conv2D(filters = 1280,kernel_size = 1,padding='same',use_bias=False, name = 'last_conv'))(x)\n",
    "x = TimeDistributed(BatchNormalization(name='last_bn'))(x)\n",
    "x = TimeDistributed(ReLU(6,name='last_relu'))(x)\n",
    "x = TimeDistributed(GlobalAveragePooling2D(name='global_average_pool'))(x)\n",
    "x = GRU(128,return_sequences=False)(x)   #lstm(no_of_neurons, input_shape=[batch, timesteps, feature])\n",
    "output = Dense(units = 7,activation = 'softmax',name='prediction')(x)\n",
    "model = Model (inputs = input_image , outputs = output , name = 'MobileNetV2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam' , loss='sparse_categorical_crossentropy',metrics =['accuracy']) \n",
    "#categorical_crossentropy (cce) produces a one-hot array containing the probable match for each category,\n",
    "#sparse_categorical_crossentropy (scce) produces a category index of the most likely matching category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1227215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99803e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,epochs = 10,validation_data = (x_test, y_test),shuffle=True,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44849376",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(20)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0.200, 1.000])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0.001, 4])\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On testing data\n",
    "predictions = model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By adding the axis argument, numpy looks at the rows and columns individually.\n",
    "#axis=1 means that the operation is performed across the rows of log_preds.\n",
    "y_pred = np.argmax(predictions,axis=1) #from log probabilities to 0 or 1\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = le.inverse_transform(y_pred)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c93973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap=\"YlGnBu\"\n",
    "#cmap=\"Blues\"\n",
    "#cmap=\"BuPu\"\n",
    "#cmap=\"Greens\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "#print(cm)\n",
    "#fig, ax = plt.subplots(figsize=(10,10)) \n",
    "plt.figure(figsize=(8,6)) \n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\",cmap=\"Greens\",vmin=0, linewidth = .5,vmax=560,annot_kws={\"size\": 10},xticklabels=[\"Black Scurf\", \"Blackleg\",\"Common Scab\", \"Dry Rot\", \"Healthy Potatoes\",\" Miscellaneous\",\" Pink Rot\"], yticklabels=[\"Black Scurf\", \"Blackleg\",\"Common Scab\", \"Dry Rot\", \"Healthy Potatoes\",\" Miscellaneous\",\" Pink Rot\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a947278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3312562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Precision = \", metrics.precision_score(y_test,y_pred,average='weighted', labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Recall = \", metrics.recall_score(y_test,y_pred,average='weighted', labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"F1 Score = \", metrics.f1_score(y_test,y_pred,average='weighted', labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9802ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 200 #Select the index of image to be loaded for testing\n",
    "n2 = 237\n",
    "n3 = 557\n",
    "\n",
    "img1 = x_test[n1]\n",
    "img2 = x_test[n2]\n",
    "img3 = x_test[n3]\n",
    "\n",
    "input_img1 = np.expand_dims(img1, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img2 = np.expand_dims(img2, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img3 = np.expand_dims(img3, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "\n",
    "\n",
    "input_img_features_1 = model.predict(input_img1)\n",
    "input_img_features_2 = model.predict(input_img2)\n",
    "input_img_features_3 = model.predict(input_img3)\n",
    "\n",
    "\n",
    "input_img_features_1 = np.argmax(input_img_features_1)\n",
    "input_img_features_2 = np.argmax(input_img_features_2)\n",
    "input_img_features_3 = np.argmax(input_img_features_3)\n",
    "\n",
    "\n",
    "input_img_features_1 = input_img_features_1.reshape(-1)\n",
    "input_img_features_2 = input_img_features_2.reshape(-1)\n",
    "input_img_features_3 = input_img_features_3.reshape(-1)\n",
    "\n",
    "\n",
    "prediction_RF_1 = le.inverse_transform(input_img_features_1)  #Reverse the label encoder to original name\n",
    "prediction_RF_2 = le.inverse_transform(input_img_features_2)  #Reverse the label encoder to original name\n",
    "prediction_RF_3 = le.inverse_transform(input_img_features_3)  #Reverse the label encoder to original name\n",
    "\n",
    "prediction_RF_text1 = ' '.join(prediction_RF_1)\n",
    "prediction_RF_text2 = ' '.join(prediction_RF_2)\n",
    "prediction_RF_text3 = ' '.join(prediction_RF_3)\n",
    "\n",
    "img1 = np.array(img1).reshape(224,224,3)\n",
    "img2 = np.array(img2).reshape(224,224,3)\n",
    "img3 = np.array(img3).reshape(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64260ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img1, (0, 0 - 55), (0 + 155, 30 - 5), (255,0,0), -1) #B2007F\n",
    "cv2.rectangle(img1, (0, 0), (224, 224), (255,0,0), 3)  #Syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "cv2.putText(img1,prediction_RF_text1, (5 , 20), cv2.FONT_HERSHEY_SIMPLEX ,0.5, (255, 255 , 255) , 1)  #Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "\n",
    "cv2.rectangle(img2, (0, 0 - 55), (0 + 155, 30 - 5), (255,0,0), -1)\n",
    "cv2.rectangle(img2, (0, 0), (224, 224), (255,0,0), 3)  #Syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "cv2.putText(img2,prediction_RF_text2, (5 , 20), cv2.FONT_HERSHEY_SIMPLEX ,0.5, (255, 255 , 255) , 1)  #Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "\n",
    "cv2.rectangle(img3, (0, 0 - 55), (0 + 155, 30 - 5), (255,0,0), -1)\n",
    "cv2.rectangle(img3, (0, 0), (224, 224), (255,0,0), 3)  #Syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "cv2.putText(img3,prediction_RF_text3, (5 , 20), cv2.FONT_HERSHEY_SIMPLEX ,0.5, (255, 255 , 255), 1)  #Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(img1)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(img2)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.axis('off')\n",
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f8c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e16b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bc9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
