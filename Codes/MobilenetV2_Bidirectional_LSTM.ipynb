{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f05fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Conv2D,Concatenate,Add,SeparableConv2D,ReLU,ZeroPadding2D,DepthwiseConv2D,TimeDistributed,LSTM,GRU,Bidirectional\n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense,BatchNormalization,Dropout,AveragePooling2D,Activation,GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbe1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\Personal Research Dataset\\\\tea sickness dataset'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_train = os.listdir('D:\\\\Personal Research Dataset\\\\tea sickness dataset')\n",
    "dataset_path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bca06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_validation = os.listdir('D:\\\\Personal Research Dataset\\\\tea sickness dataset')\n",
    "dataset_path_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086816eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_path_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_items_train=[]\n",
    "\n",
    "for item in dataset_path_train:\n",
    "  all_disease = os.listdir('D:\\\\Personal Research Dataset\\\\tea sickness dataset' +'\\\\'+item)\n",
    "  for disease in all_disease:\n",
    "    disease_items_train.append((item , str('D:\\\\Personal Research Dataset\\\\tea sickness dataset'+'\\\\'+item ) +'\\\\'+disease ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_disease_df = pd.DataFrame(data=disease_items_train,columns = ['Train_Disease_Type' ,'Train_Disease_Image'])\n",
    "train_disease_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_items_test=[]\n",
    "\n",
    "for item in dataset_path_validation:\n",
    "  all_disease = os.listdir('D:\\\\Personal Research Dataset\\\\tea sickness dataset' +'\\\\'+item)\n",
    "  for disease in all_disease:\n",
    "    disease_items_test.append((item , str('D:\\\\Personal Research Dataset\\\\tea sickness dataset'+'\\\\'+item ) +'\\\\'+disease ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disease_df = pd.DataFrame(data=disease_items_test,columns = ['Test_Disease_Type' ,'Test_Disease_Image'])\n",
    "test_disease_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "train_images = []\n",
    "train_labels = []\n",
    "path = 'D:\\\\Personal Research Dataset\\\\tea sickness dataset\\\\'\n",
    "for i in dataset_path_train:\n",
    "  data_path = path+str(i)\n",
    "  file_names = [i for i in os.listdir(data_path)]\n",
    "  #print(file_names)\n",
    "  for f in file_names:\n",
    "    img = cv2.imread(data_path+'\\\\'+f)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img,(img_width,img_height))\n",
    "    train_images.append(img)\n",
    "    train_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805aa64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "path = 'D:\\\\Personal Research Dataset\\\\tea sickness dataset\\\\'\n",
    "for i in dataset_path_validation:\n",
    "  data_path = path+str(i)\n",
    "  file_names = [i for i in os.listdir(data_path)]\n",
    "  #print(file_names)\n",
    "  for f in file_names:\n",
    "    img = cv2.imread(data_path+'\\\\'+f)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img,(img_width,img_height))\n",
    "    test_images.append(img)\n",
    "    test_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "print(test_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a82c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_images)\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test_images)\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b091791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = train_disease_df['Train_Disease_Type'].values\n",
    "#print(y_train)\n",
    "y_test = test_disease_df['Test_Disease_Type'].values\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "le =  LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)       #Label encoding for traditional Machine Leanring algorithms\n",
    "y_train_one_hot = to_categorical(y_train) # One Hot Encoding for deep learning algorithms\n",
    "\n",
    "\n",
    "le =  LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)         #Label encoding for traditional Machine Leanring algorithms\n",
    "y_test_one_hot = to_categorical(y_test)   # One Hot Encoding for deep learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7dc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8fed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(885,1,224,224, 3)\n",
    "x_test = np.array(x_test).reshape(885,1,224,224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a10c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train:\",x_train.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"x_test:\",x_test.shape)\n",
    "print(\"y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d8822",
   "metadata": {},
   "source": [
    "# Expansion Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbcbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansion_block(x,t,filters,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    total_filters = t*filters\n",
    "    x = TimeDistributed(Conv2D(total_filters,1,padding='same',use_bias=False, name =    prefix +'expand'))(x)\n",
    "    x = TimeDistributed(BatchNormalization(name=prefix +'expand_bn'))(x)\n",
    "    x = TimeDistributed(ReLU(6,name = prefix +'expand_relu'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c145f06",
   "metadata": {},
   "source": [
    "# Depthwise Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f99f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthwise_block(x,stride,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = TimeDistributed(DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv'))(x)\n",
    "    x = TimeDistributed(BatchNormalization(name=prefix +'dw_bn'))(x)\n",
    "    x = TimeDistributed(ReLU(6,name = prefix +'dw_relu'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6fcc3",
   "metadata": {},
   "source": [
    "# Projection Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_block(x,out_channels,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = TimeDistributed(Conv2D(filters=out_channels,kernel_size = 1,   padding='same',use_bias=False,name= prefix + 'compress'))(x)\n",
    "    x = TimeDistributed(BatchNormalization(name=prefix +'compress_bn'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bottleneck(x,t,filters, out_channels,stride,block_id):\n",
    "    y = expansion_block(x,t,filters,block_id)\n",
    "    y = depthwise_block(y,stride,block_id)\n",
    "    y = projection_block(y, out_channels,block_id)\n",
    "    if y.shape[-1]==x.shape[-1]:\n",
    "       y =tf.keras.layers.add([x,y])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09467ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 224\n",
    "image_width = 224\n",
    "image_channels = 3\n",
    "image_dimension = (1,image_height,image_width,image_channels)   #shape (height, width, channels)\n",
    "input_image = Input(shape = image_dimension) # inp = layers.Input((None,128,216,1), ragged=True)\n",
    "x = TimeDistributed(Conv2D(32,3,strides=(2,2),padding='same', use_bias=False))(input_image)\n",
    "x = TimeDistributed(BatchNormalization(name='conv1_bn'))(x)\n",
    "x = TimeDistributed(ReLU(6, name='conv1_relu'))(x)\n",
    "# 17 Bottlenecks\n",
    "x = depthwise_block(x,stride=1,block_id=1)\n",
    "x = projection_block(x, out_channels=16,block_id=1)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 2,block_id = 2)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 1,block_id = 3)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16)\n",
    "x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 320, stride = 1,block_id = 17)\n",
    "x = TimeDistributed(Conv2D(filters = 1280,kernel_size = 1,padding='same',use_bias=False, name = 'last_conv'))(x)\n",
    "x = TimeDistributed(BatchNormalization(name='last_bn'))(x)\n",
    "x = TimeDistributed(ReLU(6,name='last_relu'))(x)\n",
    "x = TimeDistributed(GlobalAveragePooling2D(name='global_average_pool'))(x)\n",
    "x = Bidirectional(LSTM(64,return_sequences=False))(x)   #lstm(no_of_neurons, input_shape=[batch, timesteps, feature])\n",
    "output = Dense(units = 8,activation = 'softmax',name='prediction')(x)\n",
    "model = Model (inputs = input_image , outputs = output , name = 'MobileNetV2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam' , loss='sparse_categorical_crossentropy',metrics =['accuracy']) \n",
    "#categorical_crossentropy (cce) produces a one-hot array containing the probable match for each category,\n",
    "#sparse_categorical_crossentropy (scce) produces a category index of the most likely matching category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6bbd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,epochs = 10,validation_data = (x_test, y_test),shuffle=True,batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(5)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On testing data\n",
    "predictions = model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5443d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By adding the axis argument, numpy looks at the rows and columns individually.\n",
    "#axis=1 means that the operation is performed across the rows of log_preds.\n",
    "y_pred = np.argmax(predictions,axis=1) #from log probabilities to 0 or 1\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac594423",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = le.inverse_transform(y_pred)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c181fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap=\"YlGnBu\"\n",
    "#cmap=\"Blues\"\n",
    "#cmap=\"BuPu\"\n",
    "#cmap=\"Greens\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "#print(cm)\n",
    "#fig, ax = plt.subplots(figsize=(10,10)) \n",
    "plt.figure(figsize=(8,6)) \n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\",cmap=\"Greens\",vmin=0, linewidth = .5,vmax=560,annot_kws={\"size\": 10},xticklabels=[\"Black Scurf\", \"Blackleg\",\"Common Scab\", \"Dry Rot\", \"Healthy Potatoes\",\" Miscellaneous\",\" Pink Rot\"], yticklabels=[\"Black Scurf\", \"Blackleg\",\"Common Scab\", \"Dry Rot\", \"Healthy Potatoes\",\" Miscellaneous\",\" Pink Rot\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd15cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Precision = \", metrics.precision_score(y_test,y_pred,average='weighted', labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Recall = \", metrics.recall_score(y_test,y_pred,average='weighted', labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9910fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"F1 Score = \", metrics.f1_score(y_test,y_pred,average='weighted', labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5146051",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 502 #Select the index of image to be loaded for testing\n",
    "n2 = 170\n",
    "n3 = 499\n",
    "\n",
    "img1 = x_test[n1]\n",
    "img2 = x_test[n2]\n",
    "img3 = x_test[n3]\n",
    "\n",
    "input_img1 = np.expand_dims(img1, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img2 = np.expand_dims(img2, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img3 = np.expand_dims(img3, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "\n",
    "\n",
    "input_img_features_1 = model.predict(input_img1)\n",
    "input_img_features_2 = model.predict(input_img2)\n",
    "input_img_features_3 = model.predict(input_img3)\n",
    "\n",
    "\n",
    "input_img_features_1 = np.argmax(input_img_features_1)\n",
    "input_img_features_2 = np.argmax(input_img_features_2)\n",
    "input_img_features_3 = np.argmax(input_img_features_3)\n",
    "\n",
    "\n",
    "input_img_features_1 = input_img_features_1.reshape(-1)\n",
    "input_img_features_2 = input_img_features_2.reshape(-1)\n",
    "input_img_features_3 = input_img_features_3.reshape(-1)\n",
    "\n",
    "\n",
    "prediction_RF_1 = le.inverse_transform(input_img_features_1)  #Reverse the label encoder to original name\n",
    "prediction_RF_2 = le.inverse_transform(input_img_features_2)  #Reverse the label encoder to original name\n",
    "prediction_RF_3 = le.inverse_transform(input_img_features_3)  #Reverse the label encoder to original name\n",
    "\n",
    "prediction_RF_text1 = ' '.join(prediction_RF_1)\n",
    "prediction_RF_text2 = ' '.join(prediction_RF_2)\n",
    "prediction_RF_text3 = ' '.join(prediction_RF_3)\n",
    "\n",
    "img1 = np.array(img1).reshape(224,224,3)\n",
    "img2 = np.array(img2).reshape(224,224,3)\n",
    "img3 = np.array(img3).reshape(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d25428",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img1, (0, 0 - 55), (0 + 155, 30 - 5), (255,0,0), -1) #B2007F\n",
    "cv2.rectangle(img1, (0, 0), (224, 224), (255,0,0), 3)  #Syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "cv2.putText(img1,prediction_RF_text1, (5 , 20), cv2.FONT_HERSHEY_SIMPLEX ,0.5, (255, 255 , 255) , 1)  #Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "\n",
    "cv2.rectangle(img2, (0, 0 - 55), (0 + 155, 30 - 5), (255,0,0), -1)\n",
    "cv2.rectangle(img2, (0, 0), (224, 224), (255,0,0), 3)  #Syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "cv2.putText(img2,prediction_RF_text2, (5 , 20), cv2.FONT_HERSHEY_SIMPLEX ,0.5, (255, 255 , 255) , 1)  #Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "\n",
    "cv2.rectangle(img3, (0, 0 - 55), (0 + 155, 30 - 5), (255,0,0), -1)\n",
    "cv2.rectangle(img3, (0, 0), (224, 224), (255,0,0), 3)  #Syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "cv2.putText(img3,prediction_RF_text3, (5 , 20), cv2.FONT_HERSHEY_SIMPLEX ,0.5, (255, 255 , 255), 1)  #Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(img1)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(img2)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.axis('off')\n",
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f072e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
